{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELyF3H50yNC_"
      },
      "source": [
        "## Author's notes\n",
        "### 28.10.2025\n",
        "I am starting the model creation process. The files created in the prerocessing will be used, however, I do have some issues with them.\n",
        "1) The data has not been split into train and test set during the preprocessing phase. I am aware that label encoding of categorical variables has been done and we should know all the categories for the teams, but it is still best practice to do encoding AFTER the split in order to avoid data leakage and it may be a problem in the assessment of our work by the teachers. Therefore, it would probably be for the best if this was corrected. All the preprocessing steps should be fitted to only the train data and only then used to transform the test data.\n",
        "2) Only the market values were used in the bigger dataset. I am not saying this is wrong or right and I will trust Vojta on this one, BUT there should be a very detailed explanation for why exactly we didn't use the rest of the data.\n",
        "3) There are missing values in the first observations in the derived column. I have dropped them for now, but I think a KNN imputer might do the trick, we could do some imputations and use everything.\n",
        "\n",
        "Because of the issues with the train test split, I will split the data here, but I would like to change it once it is fixed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pKBfgP1t21gI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data import, train test split and shenanigans\n",
        "The train test split should later be replaced by just loading the already split data after it has been done in preprocessing.\n",
        "After this step, the models for A0 dataset will be made in the first chunk and A1 on the second chunk of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#data import\n",
        "FILE_PATH_a0 = \"ready_data\\data_a0_encoded.csv\"\n",
        "FILE_PATH_a1 = \"ready_data\\data_a1_encoded.csv\"\n",
        "\n",
        "data_a0=pd.read_csv(FILE_PATH_a0)\n",
        "data_a1=pd.read_csv(FILE_PATH_a1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42593 entries, 0 to 42592\n",
            "Data columns (total 26 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Time                           42593 non-null  int64  \n",
            " 1   Target                         42593 non-null  int64  \n",
            " 2   HomeTeam_enc                   42593 non-null  int64  \n",
            " 3   avg_goals_in_last5_home        42115 non-null  float64\n",
            " 4   avg_goals_conceded_last5_home  42115 non-null  float64\n",
            " 5   AwayTeam_enc                   42593 non-null  int64  \n",
            " 6   avg_goals_in_last5_away        42115 non-null  float64\n",
            " 7   avg_goals_conceded_last5_away  42115 non-null  float64\n",
            " 8   Year                           42593 non-null  int64  \n",
            " 9   Month                          42593 non-null  int64  \n",
            " 10  Dayofweek                      42593 non-null  int64  \n",
            " 11  Is_weekend                     42593 non-null  int64  \n",
            " 12  Season_of_year                 42593 non-null  int64  \n",
            " 13  Country_D                      42593 non-null  bool   \n",
            " 14  Country_E                      42593 non-null  bool   \n",
            " 15  Country_F                      42593 non-null  bool   \n",
            " 16  Country_G                      42593 non-null  bool   \n",
            " 17  Country_I                      42593 non-null  bool   \n",
            " 18  Country_N                      42593 non-null  bool   \n",
            " 19  Country_P                      42593 non-null  bool   \n",
            " 20  Country_SC                     42593 non-null  bool   \n",
            " 21  Country_SP                     42593 non-null  bool   \n",
            " 22  Country_T                      42593 non-null  bool   \n",
            " 23  Division_1                     42593 non-null  bool   \n",
            " 24  Division_2                     42593 non-null  bool   \n",
            " 25  Division_3                     42593 non-null  bool   \n",
            "dtypes: bool(13), float64(4), int64(9)\n",
            "memory usage: 4.8 MB\n",
            "None\n",
            "   Time  Target  HomeTeam_enc  avg_goals_in_last5_home  \\\n",
            "0    19       1           420                      NaN   \n",
            "1    19       0           101                      NaN   \n",
            "2    19       1             8                      NaN   \n",
            "3    19       1           201                      NaN   \n",
            "4    19       0           372                      NaN   \n",
            "\n",
            "   avg_goals_conceded_last5_home  AwayTeam_enc  avg_goals_in_last5_away  \\\n",
            "0                            NaN           204                      NaN   \n",
            "1                            NaN           444                      NaN   \n",
            "2                            NaN           245                      NaN   \n",
            "3                            NaN           196                      NaN   \n",
            "4                            NaN            44                      NaN   \n",
            "\n",
            "   avg_goals_conceded_last5_away  Year  Month  ...  Country_G  Country_I  \\\n",
            "0                            NaN  2019      7  ...      False      False   \n",
            "1                            NaN  2019      7  ...      False      False   \n",
            "2                            NaN  2019      7  ...      False      False   \n",
            "3                            NaN  2019      7  ...      False      False   \n",
            "4                            NaN  2019      7  ...      False      False   \n",
            "\n",
            "   Country_N  Country_P  Country_SC  Country_SP  Country_T  Division_1  \\\n",
            "0      False      False       False       False      False       False   \n",
            "1      False      False       False       False      False       False   \n",
            "2      False      False       False       False      False       False   \n",
            "3      False      False       False       False      False       False   \n",
            "4      False      False       False       False      False       False   \n",
            "\n",
            "   Division_2  Division_3  \n",
            "0        True       False  \n",
            "1        True       False  \n",
            "2        True       False  \n",
            "3        True       False  \n",
            "4        True       False  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42593 entries, 0 to 42592\n",
            "Data columns (total 32 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Time                           42593 non-null  int64  \n",
            " 1   Target                         42593 non-null  int64  \n",
            " 2   HomeTeam_enc                   42593 non-null  int64  \n",
            " 3   avg_goals_in_last5_home        42115 non-null  float64\n",
            " 4   avg_goals_conceded_last5_home  42115 non-null  float64\n",
            " 5   AwayTeam_enc                   42593 non-null  int64  \n",
            " 6   avg_goals_in_last5_away        42115 non-null  float64\n",
            " 7   avg_goals_conceded_last5_away  42115 non-null  float64\n",
            " 8   market_decisiveness            42546 non-null  float64\n",
            " 9   expected_total_goals           42546 non-null  float64\n",
            " 10  Norm_Ah_P_home                 42546 non-null  float64\n",
            " 11  Norm_Ah_P_away                 42546 non-null  float64\n",
            " 12  ah_imbalance                   42546 non-null  float64\n",
            " 13  ah_market_confidence           42546 non-null  float64\n",
            " 14  Year                           42593 non-null  int64  \n",
            " 15  Month                          42593 non-null  int64  \n",
            " 16  Dayofweek                      42593 non-null  int64  \n",
            " 17  Is_weekend                     42593 non-null  int64  \n",
            " 18  Season_of_year                 42593 non-null  int64  \n",
            " 19  Country_D                      42593 non-null  bool   \n",
            " 20  Country_E                      42593 non-null  bool   \n",
            " 21  Country_F                      42593 non-null  bool   \n",
            " 22  Country_G                      42593 non-null  bool   \n",
            " 23  Country_I                      42593 non-null  bool   \n",
            " 24  Country_N                      42593 non-null  bool   \n",
            " 25  Country_P                      42593 non-null  bool   \n",
            " 26  Country_SC                     42593 non-null  bool   \n",
            " 27  Country_SP                     42593 non-null  bool   \n",
            " 28  Country_T                      42593 non-null  bool   \n",
            " 29  Division_1                     42593 non-null  bool   \n",
            " 30  Division_2                     42593 non-null  bool   \n",
            " 31  Division_3                     42593 non-null  bool   \n",
            "dtypes: bool(13), float64(10), int64(9)\n",
            "memory usage: 6.7 MB\n",
            "None\n",
            "   Time  Target  HomeTeam_enc  avg_goals_in_last5_home  \\\n",
            "0    19       0           307                      NaN   \n",
            "1    19       1           184                      NaN   \n",
            "2    19       0           372                      NaN   \n",
            "3    19       1           420                      NaN   \n",
            "4    19       1           201                      NaN   \n",
            "\n",
            "   avg_goals_conceded_last5_home  AwayTeam_enc  avg_goals_in_last5_away  \\\n",
            "0                            NaN           435                      1.4   \n",
            "1                            NaN           238                      1.0   \n",
            "2                            NaN            44                      1.4   \n",
            "3                            NaN           204                      1.2   \n",
            "4                            NaN           196                      0.8   \n",
            "\n",
            "   avg_goals_conceded_last5_away  market_decisiveness  expected_total_goals  \\\n",
            "0                            2.0             0.093350              1.677022   \n",
            "1                            1.2             0.121554              1.958666   \n",
            "2                            2.2             0.114610              1.644545   \n",
            "3                            0.6             0.066234              1.890909   \n",
            "4                            0.8             0.070312              1.710794   \n",
            "\n",
            "   ...  Country_G  Country_I  Country_N  Country_P  Country_SC  Country_SP  \\\n",
            "0  ...      False      False      False      False       False       False   \n",
            "1  ...      False      False      False      False       False       False   \n",
            "2  ...      False      False      False      False       False       False   \n",
            "3  ...      False      False      False      False       False       False   \n",
            "4  ...      False      False      False      False       False       False   \n",
            "\n",
            "   Country_T  Division_1  Division_2  Division_3  \n",
            "0      False       False        True       False  \n",
            "1      False        True       False       False  \n",
            "2      False       False        True       False  \n",
            "3      False       False        True       False  \n",
            "4      False       False        True       False  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nThe averaged data of the last 5 games contains missing values. \\nThis is because for the first 5 matches, it is always impossible to compute the average.\\nBecause this is a derived column, this makes sense and should not be an issue for the data.\\n'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check that everything checks out\n",
        "print(data_a0.info())\n",
        "print(data_a0.head())\n",
        "\n",
        "print(data_a1.info())\n",
        "print(data_a1.head())\n",
        "\n",
        "'''\n",
        "The averaged data of the last 5 games contains missing values. \n",
        "This is because for the first 5 matches, it is always impossible to compute the average.\n",
        "Because this is a derived column, this makes sense and should not be an issue for the data.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The country and division dummies are booleans, change that into numerical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_a0[data_a0.select_dtypes(include='bool').columns]=data_a0[data_a0.select_dtypes(include='bool').columns].astype(int)\n",
        "data_a1[data_a1.select_dtypes(include='bool').columns]=data_a1[data_a1.select_dtypes(include='bool').columns].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check that all columns have only numerical values\n",
        "non_numeric_cols0 = data_a0.select_dtypes(exclude=[np.number]).columns\n",
        "non_numeric_cols1 = data_a1.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "assert len(non_numeric_cols0)==0\n",
        "assert len(non_numeric_cols1)==0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data has been sorted chronologically in the preprocessing phase. Because this data is a time series and is likely time dependend, we will not be doing a random split of the data, but rather, a chronological one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just a check to see that we are good to keep working with the data and it's in the form we want\n",
        "assert type(data_a0)==pd.core.frame.DataFrame\n",
        "assert type(data_a1)==pd.core.frame.DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train test split, 80/20 ratio\n",
        "#for A0\n",
        "split_index_0 = int(0.8 * len(data_a0))\n",
        "\n",
        "train0 = data_a0.iloc[:split_index_0]\n",
        "test0  = data_a0.iloc[split_index_0:]\n",
        "\n",
        "X_train_0, y_train_0 = train0.drop(columns='Target'), train0['Target']\n",
        "X_test_0,  y_test_0  = test0.drop(columns='Target'),  test0['Target']\n",
        "\n",
        "#for A1\n",
        "split_index_1 = int(0.8 * len(data_a1))\n",
        "\n",
        "train1 = data_a1.iloc[:split_index_1]\n",
        "test1  = data_a1.iloc[split_index_1:]\n",
        "\n",
        "X_train_1, y_train_1 = train1.drop(columns='Target'), train1['Target']\n",
        "X_test_1,  y_test_1  = test1.drop(columns='Target'),  test1['Target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model creation A0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomForestClassifier\n",
        "Because this is a classification task and we aren't looking at a continuous target variable, we will use the RandomForestClassifier and not the RandomForestRegressor we have used in the lectures.\n",
        "\n",
        "Because we have derived the avg variables, there is some missingness in the data. I will drop the observations with missing values for now but I think it can be fixed (check author's notes at the top of this markdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#temporary solution to missing values\n",
        "X_train_0 = X_train_0.dropna()\n",
        "y_train_0 = y_train_0.loc[X_train_0.index]\n",
        "\n",
        "X_test_0 = X_test_0.dropna()\n",
        "y_test_0 = y_test_0.loc[X_test_0.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#initiate the model\n",
        "rf0_1 = RandomForestClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "#because the data is chronological, we cannot do a randomized cross-validation when choosing the model\n",
        "#we will use a rolling cross-validation instead\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=5) \n",
        "\n",
        "#this will split out data into 5 folds and we will always evaluate only based on the past, preventing leakage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#random search for some good values to use in gridsearch (hyperparameter tuning)\n",
        "#parameters to go through\n",
        "param_grid= {\n",
        "    'max_depth':[i for i in range(1, 30)],\n",
        "    'min_samples_split':[i for i in range(1,300)],\n",
        "    'min_samples_leaf':[i for i in range(1, 200)],\n",
        "    'criterion' :['gini', 'entropy', 'log_loss']\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': [18, 16, 14, 18], 'min_samples_split': [268, 239, 291, 282], 'min_samples_leaf': [58, 43, 61, 66], 'criterion': ['entropy', 'entropy', 'gini', 'log_loss']}\n"
          ]
        }
      ],
      "source": [
        "#the random search\n",
        "params={\n",
        "    'max_depth':[],\n",
        "    'min_samples_split':[],\n",
        "    'min_samples_leaf':[],\n",
        "    'criterion' :[]\n",
        "} #empty parameter grid to input the results of the random search\n",
        "for state in [1, 20, 42, 200]:\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf0_1,\n",
        "        param_distributions=param_grid,\n",
        "        cv=tscv,\n",
        "        n_iter=100,\n",
        "        random_state=state,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    random_search.fit(X_train_0, y_train_0)\n",
        "    new_params=random_search.best_params_\n",
        "    for key, value in new_params.items():\n",
        "        params[key].append(value)\n",
        "\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': [16, 18, 14], 'min_samples_split': [282, 291, 268, 239], 'min_samples_leaf': [66, 58, 43, 61], 'criterion': ['log_loss', 'gini', 'entropy']}\n"
          ]
        }
      ],
      "source": [
        "#keeping only unique values in the parameter grid\n",
        "for key in params:\n",
        "    params[key] = list(set(params[key]))\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random search is run multiple times to find some values that could be used in the grid search. As this takes some time, here are the values that it gave me when I ran the code (so they can be used immediately and without running the code):\n",
        "\n",
        "params={'max_depth': [16, 18, 14],'min_samples_split': [282, 291, 268, 239], 'min_samples_leaf': [66, 58, 43, 61], 'criterion': ['log_loss', 'gini', 'entropy']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nparams={'max_depth': [16, 18, 14],\\n        'min_samples_split': [282, 291, 268, 239],\\n        'min_samples_leaf': [66, 58, 43, 61],\\n        'criterion': ['log_loss', 'gini', 'entropy']}\\n\""
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for convenience, the params output can be loaded here\n",
        "'''\n",
        "params={'max_depth': [16, 18, 14],\n",
        "        'min_samples_split': [282, 291, 268, 239],\n",
        "        'min_samples_leaf': [66, 58, 43, 61],\n",
        "        'criterion': ['log_loss', 'gini', 'entropy']}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'criterion': 'log_loss', 'max_depth': 14, 'min_samples_leaf': 61, 'min_samples_split': 282}\n"
          ]
        }
      ],
      "source": [
        "#grid search\n",
        "grid=GridSearchCV(estimator=rf0_1,\n",
        "                  param_grid=params,\n",
        "                  n_jobs=-1, \n",
        "                  cv=tscv)\n",
        "grid.fit(X_train_0, y_train_0)\n",
        "\n",
        "best_params=grid.best_params_\n",
        "print(best_params)\n",
        "\n",
        "rf_0=grid.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As grid search takes a lot of time to be computed, here are the hyperparameter values for the best estimator for future convenience.\n",
        "\n",
        "best_params={'criterion': 'log_loss', 'max_depth': 14, 'min_samples_leaf': 61, 'min_samples_split': 282}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for convenience, the best estimator can be loaded here\n",
        "'''\n",
        "best_params={'criterion': 'log_loss', 'max_depth': 14, 'min_samples_leaf': 61, 'min_samples_split': 282}\n",
        "rf_0=RandomForestClassifier(best_params, random_state=42)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Random forest model predictions\n",
        "pred_rf_0=rf_0.predict(X_test_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tree boosting"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
