{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML2 Coursework - Complete Pipeline\n",
        "\n",
        "This notebook combines all stages of the coursework into one coherent end-to-end workflow:\n",
        "1. Data loading and initial preparation\n",
        "2. Dataset creation (A0 and A1)\n",
        "3. Feature engineering\n",
        "4. Data preprocessing\n",
        "5. Model creation and training\n",
        "6. Model evaluation\n",
        "7. Results and conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction and Setup\n",
        "\n",
        "### Libraries Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: xgboost in c:\\users\\vojte\\appdata\\roaming\\python\\python313\\site-packages (3.1.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\vojte\\appdata\\roaming\\python\\python313\\site-packages (from xgboost) (2.3.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\vojte\\appdata\\roaming\\python\\python313\\site-packages (from xgboost) (1.15.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, confusion_matrix, \n",
        "    precision_recall_curve, average_precision_score, roc_auc_score,\n",
        "    mean_squared_error\n",
        ")\n",
        "\n",
        "%pip install xgboost\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Statistical functions\n",
        "import scipy.stats as st\n",
        "\n",
        "# Set random state for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.seterr(all=\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Initial Preparation\n",
        "\n",
        "Firstly, We combine all seasons for each country into Dataframes, then we combine all country Dataframes into 1. At this stage we keep all the variables in place and we are going to create A0 and A1 datasets later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined CSVs already exist. Loading from disk...\n"
          ]
        }
      ],
      "source": [
        "# Check if combined CSVs already exist, otherwise create them\n",
        "# Try both possible directory names\n",
        "root_dir = None\n",
        "for possible_dir in [\"raw_data\", \"data\"]:\n",
        "    if os.path.exists(possible_dir):\n",
        "        root_dir = possible_dir\n",
        "        break\n",
        "\n",
        "if root_dir is None:\n",
        "    raise FileNotFoundError(\"Neither 'raw_data' nor 'data' directory found. Please check your data directory.\")\n",
        "\n",
        "output_dir = \"combined_csvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Check if combined CSVs exist\n",
        "combined_files_exist = all(\n",
        "    os.path.exists(os.path.join(output_dir, f\"{country}.csv\"))\n",
        "    for country in [\"belgium\", \"england\", \"france\", \"germany\", \"greece\", \n",
        "                    \"italy\", \"netherlands\", \"portugal\", \"scotland\", \"spain\", \"turkey\"]\n",
        ")\n",
        "\n",
        "if not combined_files_exist:\n",
        "    print(\"Combined CSVs not found. Creating them from raw data...\")\n",
        "    \n",
        "    folder_dfs = {}  # Nested dict: country -> subfolder -> CSV -> DataFrame\n",
        "    \n",
        "    # Walk through all directories\n",
        "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "        if dirpath == root_dir:\n",
        "            continue  # skip root\n",
        "        \n",
        "        # Split the path components relative to root_dir\n",
        "        rel_path = os.path.relpath(dirpath, root_dir).split(os.sep)\n",
        "        \n",
        "        # Expecting: [\"england\", \"0\"] or [\"england\", \"1\"], etc.\n",
        "        if len(rel_path) != 2:\n",
        "            continue  # skip if not exactly two levels below root\n",
        "        \n",
        "        country, subfolder = rel_path\n",
        "        \n",
        "        # Initialize nested dicts\n",
        "        folder_dfs.setdefault(country, {})\n",
        "        folder_dfs[country].setdefault(subfolder, {})\n",
        "        \n",
        "        # Loop through CSV files\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(\".csv\"):\n",
        "                file_path = os.path.join(dirpath, filename)\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path, low_memory=False)\n",
        "                    csv_name = os.path.splitext(filename)[0]  # e.g. \"1920\"\n",
        "                    folder_dfs[country][subfolder][csv_name] = df\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    \n",
        "    def concat_country_data(country_name):\n",
        "        \"\"\"Concatenate all CSVs for a given country (across all subfolders).\"\"\"\n",
        "        if country_name not in folder_dfs:\n",
        "            return pd.DataFrame()\n",
        "        # Flatten all subfolder DataFrames into one list\n",
        "        dfs = []\n",
        "        for subfolder in folder_dfs[country_name].values():\n",
        "            dfs.extend(subfolder.values())\n",
        "        # Combine them into one big DataFrame\n",
        "        if dfs:\n",
        "            return pd.concat(dfs, ignore_index=True)\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Build DataFrames per country\n",
        "    belgium_data = concat_country_data(\"belgium\")\n",
        "    england_data = concat_country_data(\"england\")\n",
        "    france_data = concat_country_data(\"france\")\n",
        "    germany_data = concat_country_data(\"germany\")\n",
        "    greece_data = concat_country_data(\"greece\")\n",
        "    italy_data = concat_country_data(\"italy\")\n",
        "    netherlands_data = concat_country_data(\"netherlands\")\n",
        "    portugal_data = concat_country_data(\"portugal\")\n",
        "    scotland_data = concat_country_data(\"scotland\")\n",
        "    spain_data = concat_country_data(\"spain\")\n",
        "    turkey_data = concat_country_data(\"turkey\")\n",
        "    \n",
        "    country_dfs = {\n",
        "        \"belgium\": belgium_data,\n",
        "        \"england\": england_data,\n",
        "        \"france\": france_data,\n",
        "        \"germany\": germany_data,\n",
        "        \"greece\": greece_data,\n",
        "        \"italy\": italy_data,\n",
        "        \"netherlands\": netherlands_data,\n",
        "        \"portugal\": portugal_data,\n",
        "        \"scotland\": scotland_data,\n",
        "        \"spain\": spain_data,\n",
        "        \"turkey\": turkey_data\n",
        "    }\n",
        "    \n",
        "    # Save combined CSVs\n",
        "    for country, df in country_dfs.items():\n",
        "        if not df.empty:\n",
        "            file_path = os.path.join(output_dir, f\"{country}.csv\")\n",
        "            df.to_csv(file_path, index=False)\n",
        "            print(f\"Saved {file_path} (shape={df.shape})\")\n",
        "    \n",
        "    print(\"\\nCombined CSVs created successfully!\")\n",
        "else:\n",
        "    print(\"Combined CSVs already exist. Loading from disk...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total dataset shape: (42593, 137)\n",
            "Columns: ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG']...\n"
          ]
        }
      ],
      "source": [
        "# Load combined country data\n",
        "b_data = pd.read_csv(os.path.join(output_dir, 'belgium.csv'), low_memory=False)\n",
        "eng_data = pd.read_csv(os.path.join(output_dir, 'england.csv'), low_memory=False)\n",
        "fr_data = pd.read_csv(os.path.join(output_dir, 'france.csv'), low_memory=False)\n",
        "d_data = pd.read_csv(os.path.join(output_dir, 'germany.csv'), low_memory=False)\n",
        "gr_data = pd.read_csv(os.path.join(output_dir, 'greece.csv'), low_memory=False)\n",
        "it_data = pd.read_csv(os.path.join(output_dir, 'italy.csv'), low_memory=False)\n",
        "ne_data = pd.read_csv(os.path.join(output_dir, 'netherlands.csv'), low_memory=False)\n",
        "por_data = pd.read_csv(os.path.join(output_dir, 'portugal.csv'), low_memory=False)\n",
        "sc_data = pd.read_csv(os.path.join(output_dir, 'scotland.csv'), low_memory=False)\n",
        "sp_data = pd.read_csv(os.path.join(output_dir, 'spain.csv'), low_memory=False)\n",
        "tur_data = pd.read_csv(os.path.join(output_dir, 'turkey.csv'), low_memory=False)\n",
        "\n",
        "# Combine all countries into one dataset\n",
        "data_og = pd.DataFrame()\n",
        "for df in [b_data, eng_data, fr_data, d_data, gr_data, it_data, ne_data, por_data, sc_data, sp_data, tur_data]:\n",
        "    data_og = pd.concat([data_og, df], ignore_index=True)\n",
        "\n",
        "print(f\"Total dataset shape: {data_og.shape}\")\n",
        "print(f\"Columns: {data_og.columns.tolist()[:10]}...\")  # Show first 10 columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Creation (A0 and A1)\n",
        "\n",
        "We create two datasets:\n",
        "- **A0**: Limited features (basic match information)\n",
        "- **A1**: Extended features with betting odds and market aggregates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 A0 Dataset Creation\n",
        "\n",
        "A0 dataset uses only basic features: Div, Date, Time, HomeTeam, AwayTeam, FTHG, FTAG, FTR. At this stage the variables used is given, thus no explanation for their choice is needed. However, we split the \"Div\" variable into 2 using the Letters as a country name and the number as a division. We also create columns \"Total_goals\" from which we derive the binary target variable. Lastly in this part, we unify the datetime format and convert time format into simple integers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A0 dataset shape: (42593, 11)\n",
            "A0 columns: ['Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'Country', 'Division', 'Total_goals', 'Target']\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "Time",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "HomeTeam",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "AwayTeam",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "FTHG",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FTAG",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FTR",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Country",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Division",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Total_goals",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Target",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "14102688-952e-4fb0-856d-99cc021e9f58",
              "rows": [
                [
                  "0",
                  "2019-07-26 00:00:00",
                  "19",
                  "Genk",
                  "Kortrijk",
                  "2",
                  "1",
                  "H",
                  "B",
                  "1",
                  "3",
                  "1"
                ],
                [
                  "1",
                  "2019-07-27 00:00:00",
                  "17",
                  "Cercle Brugge",
                  "Standard",
                  "0",
                  "2",
                  "A",
                  "B",
                  "1",
                  "2",
                  "0"
                ],
                [
                  "2",
                  "2019-07-27 00:00:00",
                  "19",
                  "St Truiden",
                  "Mouscron",
                  "0",
                  "1",
                  "A",
                  "B",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "3",
                  "2019-07-27 00:00:00",
                  "19",
                  "Waregem",
                  "Mechelen",
                  "0",
                  "2",
                  "A",
                  "B",
                  "1",
                  "2",
                  "0"
                ],
                [
                  "4",
                  "2019-07-27 00:00:00",
                  "19",
                  "Waasland-Beveren",
                  "Club Brugge",
                  "1",
                  "3",
                  "A",
                  "B",
                  "1",
                  "4",
                  "1"
                ]
              ],
              "shape": {
                "columns": 11,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>FTR</th>\n",
              "      <th>Country</th>\n",
              "      <th>Division</th>\n",
              "      <th>Total_goals</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-26</td>\n",
              "      <td>19</td>\n",
              "      <td>Genk</td>\n",
              "      <td>Kortrijk</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-07-27</td>\n",
              "      <td>17</td>\n",
              "      <td>Cercle Brugge</td>\n",
              "      <td>Standard</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-07-27</td>\n",
              "      <td>19</td>\n",
              "      <td>St Truiden</td>\n",
              "      <td>Mouscron</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-07-27</td>\n",
              "      <td>19</td>\n",
              "      <td>Waregem</td>\n",
              "      <td>Mechelen</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-27</td>\n",
              "      <td>19</td>\n",
              "      <td>Waasland-Beveren</td>\n",
              "      <td>Club Brugge</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Time          HomeTeam     AwayTeam  FTHG  FTAG FTR Country  \\\n",
              "0 2019-07-26    19              Genk     Kortrijk     2     1   H       B   \n",
              "1 2019-07-27    17     Cercle Brugge     Standard     0     2   A       B   \n",
              "2 2019-07-27    19        St Truiden     Mouscron     0     1   A       B   \n",
              "3 2019-07-27    19           Waregem     Mechelen     0     2   A       B   \n",
              "4 2019-07-27    19  Waasland-Beveren  Club Brugge     1     3   A       B   \n",
              "\n",
              "  Division  Total_goals  Target  \n",
              "0        1            3       1  \n",
              "1        1            2       0  \n",
              "2        1            1       0  \n",
              "3        1            2       0  \n",
              "4        1            4       1  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col_list_a0 = ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
        "\n",
        "def a0_data(df, feature_list):\n",
        "    \"\"\"Create A0 dataset with basic features only.\"\"\"\n",
        "    df = df[feature_list].copy()\n",
        "    # Extract Country and Division from Div column\n",
        "    df[['Country', 'Division']] = df['Div'].str.extract(r'([A-Za-z]+)(\\d+)')\n",
        "    df.drop(columns=['Div'], inplace=True)\n",
        "    # Create target variable\n",
        "    df['Total_goals'] = df['FTHG'] + df['FTAG']\n",
        "    df['Target'] = (df['Total_goals'] > 2.5).astype(int)  # 1 if more than 2.5 goals, else 0\n",
        "    # Convert Date and Time to proper formats\n",
        "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
        "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.hour\n",
        "    return df\n",
        "\n",
        "# Create A0 dataset for all countries\n",
        "data_og_a0 = a0_data(data_og, col_list_a0)\n",
        "print(f\"A0 dataset shape: {data_og_a0.shape}\")\n",
        "print(f\"A0 columns: {data_og_a0.columns.tolist()}\")\n",
        "data_og_a0.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 A1 Dataset Creation\n",
        "\n",
        "#### **Reasoning behind choosing variables for further work**  \n",
        "\n",
        "**Performance metrics**\n",
        "\n",
        "Although the dataset contains many match-level statistics, some variables cannot be used to derive meaningful and unbiased performance metrics.\n",
        "For example, while we have total shots (HS, AS) and shots on target (HST, AST), we cannot accurately calculate shot conversion rates because the data does not separate open-play goals from penalty goals. Any conversion metric would therefore be distorted by the number of penalties awarded to each team.\n",
        "\n",
        "We also exclude offside counts (HO, AO). Offsides are recorded without any information about their location relative to goal or the danger level of the attacking play. Without this context, raw offside numbers do not provide reliable insight into attacking effectiveness.\n",
        "\n",
        "Disciplinary variables (HY, AY, HR, AR, HBP, ABP) are also omitted. Although detailed, they are likely to introduce noise rather than deliver useful information about team performance quality, since card counts depend heavily on referee style and match context and are not direct indicators of playing strength.\n",
        "\n",
        "**Betting Odds Variables**\n",
        "\n",
        "For the bookmaker-based features, we use market-average odds for both the Asian Handicap and Over/Under 2.5 markets. The Asian Handicap was selected because it reflects the expected imbalance between the teams, which may translate into higher scoring potential for the stronger side.\n",
        "\n",
        "We rely on market averages rather than a single bookmaker to avoid importing the specific biases and modelling errors of any one operator. Using averages provides a more stable and representative estimate of the underlying probabilities, and reduces the risk of incorporating bookmaker-specific inaccuracies into our own model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A1 dataset shape: (42593, 15)\n",
            "A1 columns: ['Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'AvgAHH', 'AvgAHA', 'Avg>2.5', 'Avg<2.5', 'Country', 'Division', 'Total_goals', 'Target']\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Time",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "HomeTeam",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "AwayTeam",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "FTHG",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FTAG",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FTR",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "AvgAHH",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "AvgAHA",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Avg>2.5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Avg<2.5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Country",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Division",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Total_goals",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Target",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "e5eee9c8-67b9-4607-8807-5bbba093a78b",
              "rows": [
                [
                  "0",
                  "26/07/2019",
                  "19:30",
                  "Genk",
                  "Kortrijk",
                  "2",
                  "1",
                  "H",
                  "2.05",
                  "1.79",
                  "1.51",
                  "2.48",
                  "B",
                  "1",
                  "3",
                  "1"
                ],
                [
                  "1",
                  "27/07/2019",
                  "17:00",
                  "Cercle Brugge",
                  "Standard",
                  "0",
                  "2",
                  "A",
                  "1.9",
                  "1.93",
                  "1.74",
                  "2.06",
                  "B",
                  "1",
                  "2",
                  "0"
                ],
                [
                  "2",
                  "27/07/2019",
                  "19:00",
                  "St Truiden",
                  "Mouscron",
                  "0",
                  "1",
                  "A",
                  "1.95",
                  "1.88",
                  "1.82",
                  "1.98",
                  "B",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "3",
                  "27/07/2019",
                  "19:00",
                  "Waregem",
                  "Mechelen",
                  "0",
                  "2",
                  "A",
                  "1.92",
                  "1.91",
                  "1.65",
                  "2.19",
                  "B",
                  "1",
                  "2",
                  "0"
                ],
                [
                  "4",
                  "27/07/2019",
                  "19:30",
                  "Waasland-Beveren",
                  "Club Brugge",
                  "1",
                  "3",
                  "A",
                  "1.96",
                  "1.87",
                  "1.55",
                  "2.38",
                  "B",
                  "1",
                  "4",
                  "1"
                ]
              ],
              "shape": {
                "columns": 15,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>FTR</th>\n",
              "      <th>AvgAHH</th>\n",
              "      <th>AvgAHA</th>\n",
              "      <th>Avg&gt;2.5</th>\n",
              "      <th>Avg&lt;2.5</th>\n",
              "      <th>Country</th>\n",
              "      <th>Division</th>\n",
              "      <th>Total_goals</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26/07/2019</td>\n",
              "      <td>19:30</td>\n",
              "      <td>Genk</td>\n",
              "      <td>Kortrijk</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>2.05</td>\n",
              "      <td>1.79</td>\n",
              "      <td>1.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27/07/2019</td>\n",
              "      <td>17:00</td>\n",
              "      <td>Cercle Brugge</td>\n",
              "      <td>Standard</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>1.90</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.74</td>\n",
              "      <td>2.06</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27/07/2019</td>\n",
              "      <td>19:00</td>\n",
              "      <td>St Truiden</td>\n",
              "      <td>Mouscron</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1.95</td>\n",
              "      <td>1.88</td>\n",
              "      <td>1.82</td>\n",
              "      <td>1.98</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27/07/2019</td>\n",
              "      <td>19:00</td>\n",
              "      <td>Waregem</td>\n",
              "      <td>Mechelen</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2.19</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27/07/2019</td>\n",
              "      <td>19:30</td>\n",
              "      <td>Waasland-Beveren</td>\n",
              "      <td>Club Brugge</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.87</td>\n",
              "      <td>1.55</td>\n",
              "      <td>2.38</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date   Time          HomeTeam     AwayTeam  FTHG  FTAG FTR  AvgAHH  \\\n",
              "0  26/07/2019  19:30              Genk     Kortrijk     2     1   H    2.05   \n",
              "1  27/07/2019  17:00     Cercle Brugge     Standard     0     2   A    1.90   \n",
              "2  27/07/2019  19:00        St Truiden     Mouscron     0     1   A    1.95   \n",
              "3  27/07/2019  19:00           Waregem     Mechelen     0     2   A    1.92   \n",
              "4  27/07/2019  19:30  Waasland-Beveren  Club Brugge     1     3   A    1.96   \n",
              "\n",
              "   AvgAHA  Avg>2.5  Avg<2.5 Country Division  Total_goals  Target  \n",
              "0    1.79     1.51     2.48       B        1            3       1  \n",
              "1    1.93     1.74     2.06       B        1            2       0  \n",
              "2    1.88     1.82     1.98       B        1            1       0  \n",
              "3    1.91     1.65     2.19       B        1            2       0  \n",
              "4    1.87     1.55     2.38       B        1            4       1  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col_list_a1 = ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', \n",
        "               'AvgAHH', 'AvgAHA', 'Avg>2.5', 'Avg<2.5']\n",
        "\n",
        "def a1_data(df, feature_list):\n",
        "    \"\"\"Create A1 dataset with betting odds features.\"\"\"\n",
        "    # Check which columns are available\n",
        "    available_cols = [col for col in feature_list if col in df.columns]\n",
        "    df = df[available_cols].copy()\n",
        "    \n",
        "    # Extract Country and Division from Div column\n",
        "    df[['Country', 'Division']] = df['Div'].str.extract(r'([A-Za-z]+)(\\d+)')\n",
        "    df.drop(columns=['Div'], inplace=True)\n",
        "    \n",
        "    # Create target variable\n",
        "    df['Total_goals'] = df['FTHG'] + df['FTAG']\n",
        "    df['Target'] = (df['Total_goals'] > 2.5).astype(int)  # 1 if more than 2.5 goals, else 0\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Create A1 dataset for all countries\n",
        "data_big = pd.DataFrame()\n",
        "for df in [b_data, eng_data, fr_data, d_data, gr_data, it_data, ne_data, por_data, sc_data, sp_data, tur_data]:\n",
        "    data_big = pd.concat([data_big, df], ignore_index=True)\n",
        "\n",
        "big_data_a1 = a1_data(data_big, col_list_a1)\n",
        "print(f\"A1 dataset shape: {big_data_a1.shape}\")\n",
        "print(f\"A1 columns: {big_data_a1.columns.tolist()}\")\n",
        "big_data_a1.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering\n",
        "\n",
        "We engineer features for both A0 and A1 datasets, including:\n",
        "- Calendar features (Year, Month, Dayofweek, Is_weekend, Season_of_year)\n",
        "- Team encoding (LabelEncoder)\n",
        "- Rolling averages (last 5 matches)\n",
        "- Betting market features (probabilities, normalization)\n",
        "\n",
        "---\n",
        "\n",
        "### Feature engineering for A0\n",
        "\n",
        "#### **Rolling values**\n",
        "\n",
        "For every football match, we create rolling averages for goals scored and conceded in the last 5 matches.  \n",
        "Since research shows home and away matches behave differently, we treat them separately:\n",
        "\n",
        "- Home team averages use only the previous 5 *home* matches.\n",
        "- Away team averages use only the previous 5 *away* matches.\n",
        "- The same logic is used for goals conceded.\n",
        "\n",
        "This prevents data leakage and respects team-specific home/away performance patterns.\n",
        "\n",
        "#### **Time features**\n",
        "\n",
        "Datetime is decomposed into:\n",
        "- Month\n",
        "- Year\n",
        "- Day of the week\n",
        "- Weekend flag (0 = weekday, 1 = weekend)\n",
        "\n",
        "Most matches occur on weekends, so the effect may be small, but it still captures structural scheduling patterns.  \n",
        "We also assign each date a **season** (summer, autumn, winter, spring).\n",
        "\n",
        "#### **Countries and divisions**\n",
        "\n",
        "Countries and divisions are encoded using dummy variables.  \n",
        "This adds only a modest number of columns and enables league-specific structure to be learned.\n",
        "\n",
        "Finally, we drop any variables unavailable at kickoff or variables that would leak the match outcome.\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "### Additional feature engineering for A1\n",
        "\n",
        "The A1 model includes all A0 features plus betting-market-derived features.  \n",
        "We use odds available before kickoff and convert them into normalized probabilities so the model works with comparable inputs.\n",
        "\n",
        "We use **only the home-side variable** for both markets (O/U and Asian Handicap) to avoid multicollinearity.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Over/Under odds**\n",
        "\n",
        "**1. Raw implied probabilities**\n",
        "\n",
        "$$\n",
        "p_{\\text{over, raw}} = \\frac{1}{\\text{Avg}>2.5}\n",
        "$$\n",
        "\n",
        "$$\n",
        "p_{\\text{under, raw}} = \\frac{1}{\\text{Avg}<2.5}\n",
        "$$\n",
        "\n",
        "**2. Normalize probabilities (remove overround)**\n",
        "\n",
        "$$\n",
        "p_{\\text{over}} =\n",
        "\\frac{p_{\\text{over, raw}}}\n",
        "{p_{\\text{over, raw}} + p_{\\text{under, raw}}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "p_{\\text{under}} = 1 - p_{\\text{over}}\n",
        "$$\n",
        "\n",
        "**Key features kept**\n",
        "- `P_over`\n",
        "- `market_decisiveness = |P_over - 0.5|`\n",
        "\n",
        "Note: Market decisiveness measures how strongly the betting market leans toward either over or under 2.5 goals.\n",
        "Values close to 0 indicate an evenly balanced market, while values closer to 0.5 reflect a clear and confident market preference for one side.\n",
        "\n",
        "**3. Market-implied expected goals**\n",
        "\n",
        "$$\n",
        "\\text{expected\\_total\\_goals} =\n",
        "2.5 +\n",
        "\\frac{\\ln(P_{\\text{over}} + \\varepsilon)}\n",
        "{1 - (P_{\\text{over}} - 0.5) + \\varepsilon}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\varepsilon = 1 \\times 10^{-9}$ -> this avoids dividing by 0\n",
        "- Increasing $P_{over}$ increases expected total goals\n",
        "\n",
        "---\n",
        "\n",
        "#### **Asian handicap odds**\n",
        "\n",
        "**1. Raw implied probabilities**\n",
        "\n",
        "$$\n",
        "p_{\\text{AH, home}} = \\frac{1}{\\text{AvgAHH}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "p_{\\text{AH, away}} = \\frac{1}{\\text{AvgAHA}}\n",
        "$$\n",
        "\n",
        "**2. Normalize probabilities**\n",
        "\n",
        "$$\n",
        "\\text{Norm\\_Ah\\_P\\_home} =\n",
        "\\frac{p_{\\text{AH, home}}}\n",
        "{p_{\\text{AH, home}} + p_{\\text{AH, away}}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Norm\\_Ah\\_P\\_away} =\n",
        "1 - \\text{Norm\\_Ah\\_P\\_home}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "**3. Additional AH features**\n",
        "\n",
        "**Market imbalance**\n",
        "\n",
        "Measures how different the implied probabilities are between home and away AH odds.  \n",
        "Large differences mean the market strongly favors one side.\n",
        "\n",
        "$$\n",
        "\\text{ah\\_imbalance} =\n",
        "\\left| p_{\\text{AH, home}} - p_{\\text{AH, away}} \\right|\n",
        "$$\n",
        "\n",
        "**Market confidence**\n",
        "\n",
        "Captures how strongly the market believes in its preferred side, regardless of direction.  \n",
        "It simply takes the higher implied probability.\n",
        "\n",
        "$$\n",
        "\\text{ah\\_market\\_confidence} =\n",
        "\\max(p_{\\text{AH, home}},\\; p_{\\text{AH, away}})\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### **Summary of A1 betting-derived features**\n",
        "\n",
        "From Over/Under market\n",
        "- `P_over`\n",
        "- `market_decisiveness`\n",
        "- `expected_total_goals`\n",
        "\n",
        "From Asian Handicap market\n",
        "- `Norm_Ah_P_home`\n",
        "- `ah_imbalance`\n",
        "- `ah_market_confidence`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_season(date):\n",
        "    \"\"\"Get season of year: 0=winter, 1=spring, 2=summer, 3=autumn\"\"\"\n",
        "    month = date.month\n",
        "    if month in [12, 1, 2]:\n",
        "        return 0\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 1\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transf_encode_a0(df):\n",
        "    \"\"\"Transform and encode A0 dataset features.\"\"\"\n",
        "    # Sort by date to ensure chronological order for rolling averages\n",
        "    df = df.sort_values('Date').copy()\n",
        "    \n",
        "    # Team encoding - use same encoder for both HomeTeam and AwayTeam\n",
        "    team_encoder = LabelEncoder()\n",
        "    all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
        "    team_encoder.fit(all_teams)\n",
        "    \n",
        "    # Home team features\n",
        "    df['HomeTeam_enc'] = team_encoder.transform(df['HomeTeam'])\n",
        "    df = df.sort_values([\"HomeTeam_enc\", \"Date\"])\n",
        "    df['avg_goals_in_last5_home'] = (\n",
        "        df.groupby(\"HomeTeam_enc\")[\"FTHG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    df['avg_goals_conceded_last5_home'] = (\n",
        "        df.groupby(\"HomeTeam_enc\")[\"FTAG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    \n",
        "    # Away team features\n",
        "    df['AwayTeam_enc'] = team_encoder.transform(df['AwayTeam'])\n",
        "    df = df.sort_values([\"AwayTeam_enc\", \"Date\"])\n",
        "    df['avg_goals_in_last5_away'] = (\n",
        "        df.groupby(\"AwayTeam_enc\")[\"FTAG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    df['avg_goals_conceded_last5_away'] = (\n",
        "        df.groupby(\"AwayTeam_enc\")[\"FTHG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    \n",
        "    # Sort back to chronological order\n",
        "    df = df.sort_values('Date')\n",
        "    \n",
        "    # Calendar-based features\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Dayofweek'] = df['Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
        "    df['Is_weekend'] = df['Dayofweek'].isin([5, 6]).astype(int)\n",
        "    df['Season_of_year'] = df['Date'].apply(get_season)\n",
        "    \n",
        "    # Encode Country and Division as dummies\n",
        "    if 'Country' in df.columns:\n",
        "        df = pd.get_dummies(df, columns=['Country', 'Division'], drop_first=True)\n",
        "    else:\n",
        "        df = pd.get_dummies(df, columns=['Division'], drop_first=True)\n",
        "        if 'Country' in df.columns:\n",
        "            df = df.drop(columns=['Country'])\n",
        "    \n",
        "    # Drop columns used in calculations\n",
        "    df = df.drop(columns=['Total_goals', 'FTHG', 'FTAG', 'FTR', 'HomeTeam', 'AwayTeam', 'Date'])\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transf_encode_a1(df):\n",
        "    \"\"\"Transform and encode A1 dataset features with betting odds.\"\"\"\n",
        "    # Sort by date\n",
        "    df = df.sort_values('Date').copy()\n",
        "    \n",
        "    # Convert Date and Time if not already converted\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
        "        df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
        "    if not isinstance(df['Time'].iloc[0], (int, np.integer)):\n",
        "        df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.hour\n",
        "    \n",
        "    # Team encoding\n",
        "    team_encoder = LabelEncoder()\n",
        "    all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
        "    team_encoder.fit(all_teams)\n",
        "    \n",
        "    # Home team features\n",
        "    df['HomeTeam_enc'] = team_encoder.transform(df['HomeTeam'])\n",
        "    df = df.sort_values([\"HomeTeam_enc\", \"Date\"])\n",
        "    df['avg_goals_in_last5_home'] = (\n",
        "        df.groupby(\"HomeTeam_enc\")[\"FTHG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    df['avg_goals_conceded_last5_home'] = (\n",
        "        df.groupby(\"HomeTeam_enc\")[\"FTAG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    \n",
        "    # Away team features\n",
        "    df['AwayTeam_enc'] = team_encoder.transform(df['AwayTeam'])\n",
        "    df = df.sort_values([\"AwayTeam_enc\", \"Date\"])\n",
        "    df['avg_goals_in_last5_away'] = (\n",
        "        df.groupby(\"AwayTeam_enc\")[\"FTAG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    df['avg_goals_conceded_last5_away'] = (\n",
        "        df.groupby(\"AwayTeam_enc\")[\"FTHG\"]\n",
        "        .transform(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
        "    )\n",
        "    \n",
        "    # Sort back to chronological order\n",
        "    df = df.sort_values('Date')\n",
        "    \n",
        "    # Over/Under market features\n",
        "    if 'Avg>2.5' in df.columns and 'Avg<2.5' in df.columns:\n",
        "        # Convert odds to probabilities\n",
        "        df[\"p_over_raw\"] = 1 / df[\"Avg>2.5\"]\n",
        "        df[\"p_under_raw\"] = 1 / df[\"Avg<2.5\"]\n",
        "        # Normalize to remove overround\n",
        "        df[\"p_over_norm\"] = df[\"p_over_raw\"] / (df[\"p_over_raw\"] + df[\"p_under_raw\"])\n",
        "        df[\"p_under_norm\"] = 1 - df[\"p_over_norm\"]\n",
        "        \n",
        "        # Key modeling features\n",
        "        df[\"P_over\"] = df[\"p_over_norm\"]\n",
        "        df[\"market_decisiveness\"] = (df[\"P_over\"] - 0.5).abs()\n",
        "        # Expected total goals based on market probability\n",
        "        df[\"expected_total_goals\"] = 2.5 + np.log(df['P_over'] + 1e-9) / (1 - (df[\"P_over\"] - 0.5) + 1e-9)\n",
        "    \n",
        "    # Asian Handicap features\n",
        "    if 'AvgAHH' in df.columns and 'AvgAHA' in df.columns:\n",
        "        # Filter out invalid odds (must be > 1.0)\n",
        "        df = df[df['AvgAHH'] > 1.0].copy()\n",
        "        df = df[df['AvgAHA'] > 1.0].copy()\n",
        "        \n",
        "        # Convert odds to probabilities\n",
        "        df['Ah_P_home'] = 1 / df['AvgAHH']\n",
        "        df['Ah_P_away'] = 1 / df['AvgAHA']\n",
        "        \n",
        "        # Normalized probabilities\n",
        "        df['Norm_Ah_P_home'] = df['Ah_P_home'] / (df['Ah_P_home'] + df['Ah_P_away'])\n",
        "        df['Norm_Ah_P_away'] = 1 - df['Norm_Ah_P_home']\n",
        "        \n",
        "        # Market imbalance and confidence\n",
        "        df['ah_imbalance'] = (df['Ah_P_home'] - df['Ah_P_away']).abs()\n",
        "        df['ah_market_confidence'] = df[['Ah_P_home', 'Ah_P_away']].max(axis=1)\n",
        "    \n",
        "    # Calendar-based features\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Dayofweek'] = df['Date'].dt.dayofweek\n",
        "    df['Is_weekend'] = df['Dayofweek'].isin([5, 6]).astype(int)\n",
        "    df['Season_of_year'] = df['Date'].apply(get_season)\n",
        "    \n",
        "    # Encode Country and Division as dummies\n",
        "    if 'Country' in df.columns:\n",
        "        df = pd.get_dummies(df, columns=['Country', 'Division'], drop_first=True)\n",
        "    else:\n",
        "        df = pd.get_dummies(df, columns=['Division'], drop_first=True)\n",
        "        if 'Country' in df.columns:\n",
        "            df = df.drop(columns=['Country'])\n",
        "    \n",
        "    # Drop unneeded columns\n",
        "    cols_to_drop = [\n",
        "        'Total_goals', 'FTHG', 'FTAG', 'FTR', 'HomeTeam', 'AwayTeam', 'Date',\n",
        "        'p_over_raw', 'p_under_raw', 'p_over_norm', 'p_under_norm',\n",
        "        'over_price', 'P_over',\n",
        "        'Ah_P_home', 'Ah_P_away',\n",
        "        'Avg>2.5', 'Avg<2.5', 'AvgAHH', 'AvgAHA'\n",
        "    ]\n",
        "    # Only drop columns that exist\n",
        "    cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
        "    df = df.drop(columns=cols_to_drop)\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A0 encoded shape: (42593, 26)\n",
            "A0 encoded columns: ['Time', 'Target', 'HomeTeam_enc', 'avg_goals_in_last5_home', 'avg_goals_conceded_last5_home', 'AwayTeam_enc', 'avg_goals_in_last5_away', 'avg_goals_conceded_last5_away', 'Year', 'Month', 'Dayofweek', 'Is_weekend', 'Season_of_year', 'Country_D', 'Country_E', 'Country_F', 'Country_G', 'Country_I', 'Country_N', 'Country_P', 'Country_SC', 'Country_SP', 'Country_T', 'Division_1', 'Division_2', 'Division_3']\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Time",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Target",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "HomeTeam_enc",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "avg_goals_in_last5_home",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "avg_goals_conceded_last5_home",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "AwayTeam_enc",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "avg_goals_in_last5_away",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "avg_goals_conceded_last5_away",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Year",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Month",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Dayofweek",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Is_weekend",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Season_of_year",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Country_D",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_E",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_F",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_G",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_I",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_N",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_P",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_SC",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_SP",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_T",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Division_1",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Division_2",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Division_3",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "73d61713-2349-4105-9305-3e2455c537e3",
              "rows": [
                [
                  "19697",
                  "19",
                  "1",
                  "420",
                  null,
                  null,
                  "204",
                  null,
                  null,
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15758",
                  "19",
                  "0",
                  "101",
                  null,
                  null,
                  "444",
                  null,
                  null,
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15757",
                  "19",
                  "1",
                  "8",
                  null,
                  null,
                  "245",
                  null,
                  null,
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15760",
                  "19",
                  "1",
                  "201",
                  null,
                  null,
                  "196",
                  null,
                  null,
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15763",
                  "19",
                  "0",
                  "372",
                  null,
                  null,
                  "44",
                  null,
                  null,
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ]
              ],
              "shape": {
                "columns": 26,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Target</th>\n",
              "      <th>HomeTeam_enc</th>\n",
              "      <th>avg_goals_in_last5_home</th>\n",
              "      <th>avg_goals_conceded_last5_home</th>\n",
              "      <th>AwayTeam_enc</th>\n",
              "      <th>avg_goals_in_last5_away</th>\n",
              "      <th>avg_goals_conceded_last5_away</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>...</th>\n",
              "      <th>Country_G</th>\n",
              "      <th>Country_I</th>\n",
              "      <th>Country_N</th>\n",
              "      <th>Country_P</th>\n",
              "      <th>Country_SC</th>\n",
              "      <th>Country_SP</th>\n",
              "      <th>Country_T</th>\n",
              "      <th>Division_1</th>\n",
              "      <th>Division_2</th>\n",
              "      <th>Division_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19697</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>420</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>204</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15758</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15757</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>245</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15760</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>196</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15763</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>372</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time  Target  HomeTeam_enc  avg_goals_in_last5_home  \\\n",
              "19697    19       1           420                      NaN   \n",
              "15758    19       0           101                      NaN   \n",
              "15757    19       1             8                      NaN   \n",
              "15760    19       1           201                      NaN   \n",
              "15763    19       0           372                      NaN   \n",
              "\n",
              "       avg_goals_conceded_last5_home  AwayTeam_enc  avg_goals_in_last5_away  \\\n",
              "19697                            NaN           204                      NaN   \n",
              "15758                            NaN           444                      NaN   \n",
              "15757                            NaN           245                      NaN   \n",
              "15760                            NaN           196                      NaN   \n",
              "15763                            NaN            44                      NaN   \n",
              "\n",
              "       avg_goals_conceded_last5_away  Year  Month  ...  Country_G  Country_I  \\\n",
              "19697                            NaN  2019      7  ...      False      False   \n",
              "15758                            NaN  2019      7  ...      False      False   \n",
              "15757                            NaN  2019      7  ...      False      False   \n",
              "15760                            NaN  2019      7  ...      False      False   \n",
              "15763                            NaN  2019      7  ...      False      False   \n",
              "\n",
              "       Country_N  Country_P  Country_SC  Country_SP  Country_T  Division_1  \\\n",
              "19697      False      False       False       False      False       False   \n",
              "15758      False      False       False       False      False       False   \n",
              "15757      False      False       False       False      False       False   \n",
              "15760      False      False       False       False      False       False   \n",
              "15763      False      False       False       False      False       False   \n",
              "\n",
              "       Division_2  Division_3  \n",
              "19697        True       False  \n",
              "15758        True       False  \n",
              "15757        True       False  \n",
              "15760        True       False  \n",
              "15763        True       False  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply feature engineering to A0 dataset\n",
        "data_og_a0_encoded = transf_encode_a0(data_og_a0.copy())\n",
        "print(f\"A0 encoded shape: {data_og_a0_encoded.shape}\")\n",
        "print(f\"A0 encoded columns: {data_og_a0_encoded.columns.tolist()}\")\n",
        "data_og_a0_encoded.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A1 encoded shape: (42545, 32)\n",
            "A1 encoded columns: ['Time', 'Target', 'HomeTeam_enc', 'avg_goals_in_last5_home', 'avg_goals_conceded_last5_home', 'AwayTeam_enc', 'avg_goals_in_last5_away', 'avg_goals_conceded_last5_away', 'market_decisiveness', 'expected_total_goals', 'Norm_Ah_P_home', 'Norm_Ah_P_away', 'ah_imbalance', 'ah_market_confidence', 'Year', 'Month', 'Dayofweek', 'Is_weekend', 'Season_of_year', 'Country_D', 'Country_E', 'Country_F', 'Country_G', 'Country_I', 'Country_N', 'Country_P', 'Country_SC', 'Country_SP', 'Country_T', 'Division_1', 'Division_2', 'Division_3']\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Time",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Target",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "HomeTeam_enc",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "avg_goals_in_last5_home",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "avg_goals_conceded_last5_home",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "AwayTeam_enc",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "avg_goals_in_last5_away",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "avg_goals_conceded_last5_away",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "market_decisiveness",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "expected_total_goals",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Norm_Ah_P_home",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Norm_Ah_P_away",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "ah_imbalance",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "ah_market_confidence",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Year",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Month",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Dayofweek",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Is_weekend",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Season_of_year",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Country_D",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_E",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_F",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_G",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_I",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_N",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_P",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_SC",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_SP",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Country_T",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Division_1",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Division_2",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Division_3",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "705ad24a-832e-43fa-b480-7aaba44f4d2b",
              "rows": [
                [
                  "19697",
                  "19",
                  "1",
                  "420",
                  null,
                  null,
                  "204",
                  null,
                  null,
                  "0.06623376623376631",
                  "1.8909093640818733",
                  "0.49090909090909085",
                  "0.5090909090909091",
                  "0.01889644746787611",
                  "0.5291005291005292",
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15758",
                  "19",
                  "0",
                  "101",
                  null,
                  null,
                  "444",
                  null,
                  null,
                  "0.05613577023498695",
                  "1.7309354800778518",
                  "0.4510309278350516",
                  "0.5489690721649484",
                  "0.10194500335345402",
                  "0.5714285714285714",
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15757",
                  "19",
                  "1",
                  "8",
                  null,
                  null,
                  "245",
                  null,
                  null,
                  "0.14476885644768855",
                  "1.5958990688475079",
                  "0.4715025906735752",
                  "0.5284974093264247",
                  "0.05925447101917686",
                  "0.5494505494505494",
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15760",
                  "19",
                  "1",
                  "201",
                  null,
                  null,
                  "196",
                  null,
                  null,
                  "0.0703125",
                  "1.7107939731894495",
                  "0.4883116883116883",
                  "0.5116883116883117",
                  "0.024300680419051757",
                  "0.5319148936170213",
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ],
                [
                  "15763",
                  "19",
                  "0",
                  "372",
                  null,
                  null,
                  "44",
                  null,
                  null,
                  "0.11460957178841313",
                  "1.644544977920276",
                  "0.4805194805194806",
                  "0.5194805194805194",
                  "0.04054054054054046",
                  "0.5405405405405405",
                  "2019",
                  "7",
                  "4",
                  "0",
                  "2",
                  "False",
                  "False",
                  "True",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "False",
                  "True",
                  "False"
                ]
              ],
              "shape": {
                "columns": 32,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Target</th>\n",
              "      <th>HomeTeam_enc</th>\n",
              "      <th>avg_goals_in_last5_home</th>\n",
              "      <th>avg_goals_conceded_last5_home</th>\n",
              "      <th>AwayTeam_enc</th>\n",
              "      <th>avg_goals_in_last5_away</th>\n",
              "      <th>avg_goals_conceded_last5_away</th>\n",
              "      <th>market_decisiveness</th>\n",
              "      <th>expected_total_goals</th>\n",
              "      <th>...</th>\n",
              "      <th>Country_G</th>\n",
              "      <th>Country_I</th>\n",
              "      <th>Country_N</th>\n",
              "      <th>Country_P</th>\n",
              "      <th>Country_SC</th>\n",
              "      <th>Country_SP</th>\n",
              "      <th>Country_T</th>\n",
              "      <th>Division_1</th>\n",
              "      <th>Division_2</th>\n",
              "      <th>Division_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19697</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>420</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>204</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.066234</td>\n",
              "      <td>1.890909</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15758</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.056136</td>\n",
              "      <td>1.730935</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15757</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>245</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.144769</td>\n",
              "      <td>1.595899</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15760</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>196</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.070312</td>\n",
              "      <td>1.710794</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15763</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>372</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.114610</td>\n",
              "      <td>1.644545</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time  Target  HomeTeam_enc  avg_goals_in_last5_home  \\\n",
              "19697    19       1           420                      NaN   \n",
              "15758    19       0           101                      NaN   \n",
              "15757    19       1             8                      NaN   \n",
              "15760    19       1           201                      NaN   \n",
              "15763    19       0           372                      NaN   \n",
              "\n",
              "       avg_goals_conceded_last5_home  AwayTeam_enc  avg_goals_in_last5_away  \\\n",
              "19697                            NaN           204                      NaN   \n",
              "15758                            NaN           444                      NaN   \n",
              "15757                            NaN           245                      NaN   \n",
              "15760                            NaN           196                      NaN   \n",
              "15763                            NaN            44                      NaN   \n",
              "\n",
              "       avg_goals_conceded_last5_away  market_decisiveness  \\\n",
              "19697                            NaN             0.066234   \n",
              "15758                            NaN             0.056136   \n",
              "15757                            NaN             0.144769   \n",
              "15760                            NaN             0.070312   \n",
              "15763                            NaN             0.114610   \n",
              "\n",
              "       expected_total_goals  ...  Country_G  Country_I  Country_N  Country_P  \\\n",
              "19697              1.890909  ...      False      False      False      False   \n",
              "15758              1.730935  ...      False      False      False      False   \n",
              "15757              1.595899  ...      False      False      False      False   \n",
              "15760              1.710794  ...      False      False      False      False   \n",
              "15763              1.644545  ...      False      False      False      False   \n",
              "\n",
              "       Country_SC  Country_SP  Country_T  Division_1  Division_2  Division_3  \n",
              "19697       False       False      False       False        True       False  \n",
              "15758       False       False      False       False        True       False  \n",
              "15757       False       False      False       False        True       False  \n",
              "15760       False       False      False       False        True       False  \n",
              "15763       False       False      False       False        True       False  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply feature engineering to A1 dataset\n",
        "data_big_a1_encoded = transf_encode_a1(big_data_a1.copy())\n",
        "print(f\"A1 encoded shape: {data_big_a1_encoded.shape}\")\n",
        "print(f\"A1 encoded columns: {data_big_a1_encoded.columns.tolist()}\")\n",
        "data_big_a1_encoded.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Preprocessing\n",
        "\n",
        "Before model training, we need to:\n",
        "- Fix data types (boolean dummies to int)\n",
        "- Remove infinity values\n",
        "- Handle missing values\n",
        "- Sort chronologically\n",
        "- Split into train/test sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data preprocessing complete.\n",
            "A0 shape: (42593, 26)\n",
            "A1 shape: (42545, 32)\n",
            "\n",
            "Non-numeric columns in A0: []\n",
            "Non-numeric columns in A1: []\n"
          ]
        }
      ],
      "source": [
        "# Fix boolean dummies to int\n",
        "for df in [data_og_a0_encoded, data_big_a1_encoded]:\n",
        "    bool_cols = df.select_dtypes(include='bool').columns\n",
        "    if len(bool_cols) > 0:\n",
        "        df[bool_cols] = df[bool_cols].astype(int)\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "for df in [data_og_a0_encoded, data_big_a1_encoded]:\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Note: Data should already be sorted chronologically from feature engineering step\n",
        "# Reset index to ensure clean indexing\n",
        "for df in [data_og_a0_encoded, data_big_a1_encoded]:\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Data preprocessing complete.\")\n",
        "print(f\"A0 shape: {data_og_a0_encoded.shape}\")\n",
        "print(f\"A1 shape: {data_big_a1_encoded.shape}\")\n",
        "\n",
        "# Check for non-numeric columns\n",
        "non_numeric_a0 = data_og_a0_encoded.select_dtypes(exclude=[np.number]).columns\n",
        "non_numeric_a1 = data_big_a1_encoded.select_dtypes(exclude=[np.number]).columns\n",
        "print(f\"\\nNon-numeric columns in A0: {list(non_numeric_a0)}\")\n",
        "print(f\"Non-numeric columns in A1: {list(non_numeric_a1)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A0 - Train: (34074, 25), Test: (8519, 25)\n",
            "A1 - Train: (34036, 31), Test: (8509, 31)\n"
          ]
        }
      ],
      "source": [
        "# Chronological train/test split (80/20)\n",
        "# Since data is already sorted chronologically from feature engineering, we split by index\n",
        "\n",
        "def chrono_split(df, test_frac=0.2):\n",
        "    \"\"\"Split dataframe chronologically (assumes data is already sorted by date).\"\"\"\n",
        "    df = df.reset_index(drop=True)\n",
        "    cut = int(np.floor((1 - test_frac) * len(df)))\n",
        "    return df.iloc[:cut].copy(), df.iloc[cut:].copy()\n",
        "\n",
        "# Split A0 dataset\n",
        "train0, test0 = chrono_split(data_og_a0_encoded)\n",
        "X_train_0 = train0.drop(columns='Target')\n",
        "y_train_0 = train0['Target'].astype(int)\n",
        "X_test_0 = test0.drop(columns='Target')\n",
        "y_test_0 = test0['Target'].astype(int)\n",
        "\n",
        "# Split A1 dataset\n",
        "train1, test1 = chrono_split(data_big_a1_encoded)\n",
        "X_train_1 = train1.drop(columns='Target')\n",
        "y_train_1 = train1['Target'].astype(int)\n",
        "X_test_1 = test1.drop(columns='Target')\n",
        "y_test_1 = test1['Target'].astype(int)\n",
        "\n",
        "print(f\"A0 - Train: {X_train_0.shape}, Test: {X_test_0.shape}\")\n",
        "print(f\"A1 - Train: {X_train_1.shape}, Test: {X_test_1.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete.\n",
            "A0 processed - Train: (34074, 25), Test: (8519, 25)\n",
            "A1 processed - Train: (34036, 31), Test: (8509, 31)\n"
          ]
        }
      ],
      "source": [
        "# Build preprocessing pipeline\n",
        "def build_preprocessor(X, for_linear=False, use_knn=True):\n",
        "    \"\"\"Build preprocessing pipeline with imputation.\"\"\"\n",
        "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "    \n",
        "    num_steps = [(\"impute_num\", KNNImputer(n_neighbors=5))] if use_knn else \\\n",
        "                [(\"impute_num\", SimpleImputer(strategy=\"median\"))]\n",
        "    if for_linear:\n",
        "        num_steps.append((\"scale\", StandardScaler()))\n",
        "    \n",
        "    num_pipe = Pipeline(num_steps)\n",
        "    cat_pipe = Pipeline([\n",
        "        (\"impute_cat\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
        "    ])\n",
        "    \n",
        "    pre = ColumnTransformer(\n",
        "        [(\"num\", num_pipe, num_cols),\n",
        "         (\"cat\", cat_pipe, cat_cols)],\n",
        "        remainder=\"drop\",\n",
        "        sparse_threshold=0.3\n",
        "    )\n",
        "    return pre\n",
        "\n",
        "# Create preprocessors for A0 and A1\n",
        "pre0 = build_preprocessor(X_train_0, for_linear=False, use_knn=True)\n",
        "pre1 = build_preprocessor(X_train_1, for_linear=False, use_knn=True)\n",
        "\n",
        "# Fit preprocessors and transform data\n",
        "X_train_0_processed = pre0.fit_transform(X_train_0)\n",
        "X_test_0_processed = pre0.transform(X_test_0)\n",
        "X_train_1_processed = pre1.fit_transform(X_train_1)\n",
        "X_test_1_processed = pre1.transform(X_test_1)\n",
        "\n",
        "print(\"Preprocessing complete.\")\n",
        "print(f\"A0 processed - Train: {X_train_0_processed.shape}, Test: {X_test_0_processed.shape}\")\n",
        "print(f\"A1 processed - Train: {X_train_1_processed.shape}, Test: {X_test_1_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Creation and Training\n",
        "\n",
        "We train three types of models for both A0 and A1 datasets:\n",
        "- Random Forest Classifier\n",
        "- XGBoost Classifier\n",
        "- Logistic Regression\n",
        "\n",
        "We use TimeSeriesSplit for cross-validation to prevent data leakage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series cross-validation\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Convert sparse matrices to dense if needed (for some models)\n",
        "from scipy.sparse import issparse\n",
        "if issparse(X_train_0_processed):\n",
        "    X_train_0_processed = X_train_0_processed.toarray()\n",
        "    X_test_0_processed = X_test_0_processed.toarray()\n",
        "if issparse(X_train_1_processed):\n",
        "    X_train_1_processed = X_train_1_processed.toarray()\n",
        "    X_test_1_processed = X_test_1_processed.toarray()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 A0 Models\n",
        "\n",
        "#### Random Forest Classifier (A0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest A0 trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# Random Forest A0 - Using pre-computed best parameters\n",
        "# Best parameters from grid search:\n",
        "# {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_leaf': 61, 'min_samples_split': 282}\n",
        "\n",
        "rf_a0 = RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    criterion='log_loss',\n",
        "    max_depth=14,\n",
        "    min_samples_leaf=61,\n",
        "    min_samples_split=282,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "rf_a0.fit(X_train_0_processed, y_train_0)\n",
        "pred_rf_a0 = rf_a0.predict(X_test_0_processed)\n",
        "\n",
        "print(\"Random Forest A0 trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost Classifier (A0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost A0 trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# XGBoost A0 - Using pre-computed best parameters\n",
        "# Best parameters from grid search:\n",
        "# {'colsample_bytree': 0.8061000499878099, 'learning_rate': 0.021098111168009435, \n",
        "#  'max_depth': 5, 'n_estimators': 154, 'subsample': 0.9044486520109609}\n",
        "\n",
        "xgb_a0 = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    n_estimators=154,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.021098111168009435,\n",
        "    subsample=0.9044486520109609,\n",
        "    colsample_bytree=0.8061000499878099,\n",
        "    tree_method='hist',\n",
        "    random_state=RANDOM_STATE,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_a0.fit(X_train_0_processed, y_train_0)\n",
        "pred_xgb_a0 = xgb_a0.predict(X_test_0_processed)\n",
        "\n",
        "print(\"XGBoost A0 trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logistic Regression (A0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression A0 trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression A0 with time series cross-validation\n",
        "logreg_a0 = LogisticRegressionCV(\n",
        "    max_iter=10000,\n",
        "    cv=tscv,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "logreg_a0.fit(X_train_0_processed, y_train_0)\n",
        "pred_logreg_a0 = logreg_a0.predict(X_test_0_processed)\n",
        "\n",
        "print(\"Logistic Regression A0 trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 A1 Models\n",
        "\n",
        "#### Random Forest Classifier (A1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest A1 trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# Random Forest A1 - Using pre-computed best parameters\n",
        "# Best parameters from grid search:\n",
        "# {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_leaf': 128, 'min_samples_split': 297}\n",
        "\n",
        "rf_a1 = RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    criterion='log_loss',\n",
        "    max_depth=15,\n",
        "    min_samples_leaf=128,\n",
        "    min_samples_split=297,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "rf_a1.fit(X_train_1_processed, y_train_1)\n",
        "pred_rf_a1 = rf_a1.predict(X_test_1_processed)\n",
        "\n",
        "print(\"Random Forest A1 trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost Classifier (A1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost A1 trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# XGBoost A1 - Using pre-computed best parameters\n",
        "# Best parameters from grid search:\n",
        "# {'colsample_bytree': 0.9048980247717036, 'learning_rate': 0.03257244251360208,\n",
        "#  'max_depth': 4, 'n_estimators': 32, 'subsample': 0.8405358828849236}\n",
        "\n",
        "xgb_a1 = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    n_estimators=32,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.03257244251360208,\n",
        "    subsample=0.8405358828849236,\n",
        "    colsample_bytree=0.9048980247717036,\n",
        "    tree_method='hist',\n",
        "    random_state=RANDOM_STATE,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_a1.fit(X_train_1_processed, y_train_1)\n",
        "pred_xgb_a1 = xgb_a1.predict(X_test_1_processed)\n",
        "\n",
        "print(\"XGBoost A1 trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logistic Regression (A1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression A1 trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression A1 with time series cross-validation\n",
        "logreg_a1 = LogisticRegressionCV(\n",
        "    max_iter=10000,\n",
        "    cv=tscv,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "logreg_a1.fit(X_train_1_processed, y_train_1)\n",
        "pred_logreg_a1 = logreg_a1.predict(X_test_1_processed)\n",
        "\n",
        "print(\"Logistic Regression A1 trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Evaluation\n",
        "\n",
        "We evaluate all models using multiple metrics:\n",
        "- Accuracy (with 95% confidence intervals)\n",
        "- F1-score\n",
        "- Precision-Recall (Average Precision)\n",
        "- ROC-AUC\n",
        "- Confusion matrices\n",
        "- Threshold optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_thr_by_f1(y_true, prob):\n",
        "    \"\"\"Find best threshold by maximizing F1 score.\"\"\"\n",
        "    p, r, t = precision_recall_curve(y_true, prob)\n",
        "    f1 = 2 * p * r / (p + r + 1e-9)\n",
        "    i = np.nanargmax(f1)\n",
        "    return float(t[i]) if i < len(t) else 0.5\n",
        "\n",
        "def acc_ci(y_true, y_pred, B=1000, seed=0):\n",
        "    \"\"\"Calculate 95% confidence interval for accuracy using bootstrap.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = len(y_true)\n",
        "    vals = []\n",
        "    for _ in range(B):\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        vals.append(accuracy_score(y_true[idx], y_pred[idx]))\n",
        "    return tuple(np.percentile(vals, [2.5, 97.5]))\n",
        "\n",
        "def fit_and_eval(model, Xtr, ytr, Xte, yte, label):\n",
        "    \"\"\"Train model and evaluate with threshold optimization.\"\"\"\n",
        "    # Get probabilities\n",
        "    pr_tr = model.predict_proba(Xtr)[:, 1]\n",
        "    thr = best_thr_by_f1(ytr.values, pr_tr)\n",
        "    \n",
        "    pr_te = model.predict_proba(Xte)[:, 1]\n",
        "    pred = (pr_te >= thr).astype(int)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(yte, pred)\n",
        "    f1 = f1_score(yte, pred)\n",
        "    ap = average_precision_score(yte, pr_te)\n",
        "    auc = roc_auc_score(yte, pr_te)\n",
        "    cm = confusion_matrix(yte, pred, labels=[0, 1])\n",
        "    lo, hi = acc_ci(yte.values, pred)\n",
        "    \n",
        "    print(f\"{label}: thr={thr:.3f} | ACC={acc:.4f} (95% [{lo:.4f},{hi:.4f}]) | \"\n",
        "          f\"F1={f1:.4f} | AP={ap:.4f} | AUC={auc:.4f}\")\n",
        "    print(\"Confusion matrix [TN FP; FN TP]:\")\n",
        "    print(cm, \"\\n\")\n",
        "    \n",
        "    return {\n",
        "        'label': label, 'thr': thr, 'acc': acc, 'f1': f1, \n",
        "        'ap': ap, 'auc': auc, 'cm': cm, 'pred': pred, 'proba': pr_te\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== A0 Models ===\n",
            "RF A0: thr=0.436 | ACC=0.5212 (95% [0.5111,0.5320]) | F1=0.6658 | AP=0.5746 | AUC=0.5571\n",
            "Confusion matrix [TN FP; FN TP]:\n",
            "[[ 377 3738]\n",
            " [ 341 4063]] \n",
            "\n",
            "XGB A0: thr=0.406 | ACC=0.5194 (95% [0.5097,0.5303]) | F1=0.6742 | AP=0.5743 | AUC=0.5580\n",
            "Confusion matrix [TN FP; FN TP]:\n",
            "[[ 189 3926]\n",
            " [ 168 4236]] \n",
            "\n",
            "LogReg A0: thr=0.367 | ACC=0.5165 (95% [0.5066,0.5275]) | F1=0.6800 | AP=0.5700 | AUC=0.5537\n",
            "Confusion matrix [TN FP; FN TP]:\n",
            "[[  23 4092]\n",
            " [  27 4377]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate A0 models\n",
        "print(\"=== A0 Models ===\")\n",
        "res_rf_a0 = fit_and_eval(rf_a0, X_train_0_processed, y_train_0, X_test_0_processed, y_test_0, \"RF A0\")\n",
        "res_xgb_a0 = fit_and_eval(xgb_a0, X_train_0_processed, y_train_0, X_test_0_processed, y_test_0, \"XGB A0\")\n",
        "res_logreg_a0 = fit_and_eval(logreg_a0, X_train_0_processed, y_train_0, X_test_0_processed, y_test_0, \"LogReg A0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== A1 Models ===\n",
            "RF A1: thr=0.396 | ACC=0.5306 (95% [0.5199,0.5411]) | F1=0.6749 | AP=0.6145 | AUC=0.5987\n",
            "Confusion matrix [TN FP; FN TP]:\n",
            "[[ 370 3739]\n",
            " [ 255 4145]] \n",
            "\n",
            "XGB A1: thr=0.401 | ACC=0.5238 (95% [0.5128,0.5337]) | F1=0.6816 | AP=0.6167 | AUC=0.6021\n",
            "Confusion matrix [TN FP; FN TP]:\n",
            "[[ 119 3990]\n",
            " [  62 4338]] \n",
            "\n",
            "LogReg A1: thr=0.330 | ACC=0.5234 (95% [0.5123,0.5329]) | F1=0.6816 | AP=0.6161 | AUC=0.6019\n",
            "Confusion matrix [TN FP; FN TP]:\n",
            "[[ 113 3996]\n",
            " [  59 4341]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate A1 models\n",
        "print(\"=== A1 Models ===\")\n",
        "res_rf_a1 = fit_and_eval(rf_a1, X_train_1_processed, y_train_1, X_test_1_processed, y_test_1, \"RF A1\")\n",
        "res_xgb_a1 = fit_and_eval(xgb_a1, X_train_1_processed, y_train_1, X_test_1_processed, y_test_1, \"XGB A1\")\n",
        "res_logreg_a1 = fit_and_eval(logreg_a1, X_train_1_processed, y_train_1, X_test_1_processed, y_test_1, \"LogReg A1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Per-Country Accuracy Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Per-Country Accuracy Comparison:\n",
            "  Country  accuracy_A0  accuracy_A1      lift\n",
            "1       E     0.515897     0.561069  0.045172\n",
            "8      SP     0.537634     0.577713  0.040078\n",
            "6       P     0.594086     0.633423  0.039337\n",
            "9       T     0.530806     0.568720  0.037915\n",
            "0       D     0.572573     0.603217  0.030644\n",
            "4       I     0.539957     0.562635  0.022678\n",
            "2       F     0.533069     0.553642  0.020574\n",
            "5       N     0.590296     0.607046  0.016750\n",
            "3       G     0.530686     0.537906  0.007220\n",
            "7      SC     0.521348     0.521935  0.000586\n"
          ]
        }
      ],
      "source": [
        "def per_country_acc(fitted_model, Xte, yte, preprocessor):\n",
        "    \"\"\"Calculate per-country accuracy.\"\"\"\n",
        "    # Get country information from dummies\n",
        "    country_cols = [c for c in Xte.columns if c.startswith(\"Country_\")]\n",
        "    if not country_cols:\n",
        "        print(\"No Country info present.\")\n",
        "        return None\n",
        "    \n",
        "    # Transform test data\n",
        "    Xte_processed = preprocessor.transform(Xte)\n",
        "    if issparse(Xte_processed):\n",
        "        Xte_processed = Xte_processed.toarray()\n",
        "    \n",
        "    # Get country labels\n",
        "    country = Xte[country_cols].idxmax(axis=1).str.replace(\"Country_\", \"\", regex=False)\n",
        "    \n",
        "    # Get predictions\n",
        "    probs = fitted_model.predict_proba(Xte_processed)[:, 1]\n",
        "    pred = (probs >= 0.5).astype(int)\n",
        "    \n",
        "    # Calculate per-country accuracy\n",
        "    tmp = pd.DataFrame({\"Country\": country, \"y\": yte.values, \"p\": pred})\n",
        "    return tmp.groupby(\"Country\").apply(lambda g: accuracy_score(g[\"y\"], g[\"p\"]))\\\n",
        "              .rename(\"accuracy\").reset_index()\n",
        "\n",
        "# Calculate per-country accuracy for best models (using Random Forest)\n",
        "pc_rf_a0 = per_country_acc(rf_a0, X_test_0, y_test_0, pre0)\n",
        "pc_rf_a1 = per_country_acc(rf_a1, X_test_1, y_test_1, pre1)\n",
        "\n",
        "if pc_rf_a0 is not None and pc_rf_a1 is not None:\n",
        "    pc = pc_rf_a0.merge(pc_rf_a1, on=\"Country\", suffixes=(\"_A0\", \"_A1\"))\n",
        "    pc[\"lift\"] = pc[\"accuracy_A1\"] - pc[\"accuracy_A0\"]\n",
        "    print(\"\\nPer-Country Accuracy Comparison:\")\n",
        "    print(pc.sort_values(\"lift\", ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Per-Country Accuracy Comparison:\n",
            "  Country  accuracy_A0  accuracy_A1      lift\n",
            "6       P     0.564516     0.622642  0.058125\n",
            "1       E     0.514201     0.569126  0.054925\n",
            "9       T     0.504739     0.556872  0.052133\n",
            "0       D     0.573464     0.606792  0.033328\n",
            "8      SP     0.545455     0.578690  0.033236\n",
            "2       F     0.533069     0.564238  0.031170\n",
            "4       I     0.536717     0.566955  0.030238\n",
            "7      SC     0.528090     0.530934  0.002844\n",
            "5       N     0.603774     0.582656 -0.021118\n",
            "3       G     0.559567     0.516245 -0.043321\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'XGBClassifier' object has no attribute 'accuracy_score'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPer-Country Accuracy Comparison:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(pc.sort_values(\u001b[33m\"\u001b[39m\u001b[33mlift\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mxgb_a0\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccuracy_score\u001b[49m(X_test_0_processed, y_test_0))\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(xgb_a1.accuracy_score(X_test_1_processed, y_test_1))\n",
            "\u001b[31mAttributeError\u001b[39m: 'XGBClassifier' object has no attribute 'accuracy_score'"
          ]
        }
      ],
      "source": [
        "pc_rf_a0 = per_country_acc(xgb_a0, X_test_0, y_test_0, pre0)\n",
        "pc_rf_a1 = per_country_acc(xgb_a1, X_test_1, y_test_1, pre1)\n",
        "\n",
        "if pc_rf_a0 is not None and pc_rf_a1 is not None:\n",
        "    pc = pc_rf_a0.merge(pc_rf_a1, on=\"Country\", suffixes=(\"_A0\", \"_A1\"))\n",
        "    pc[\"lift\"] = pc[\"accuracy_A1\"] - pc[\"accuracy_A0\"]\n",
        "    print(\"\\nPer-Country Accuracy Comparison:\")\n",
        "    print(pc.sort_values(\"lift\", ascending=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Per-Country Accuracy Comparison:\n",
            "  Country  accuracy_A0  accuracy_A1      lift\n",
            "8      SP     0.528837     0.586510  0.057674\n",
            "1       E     0.526494     0.563613  0.037119\n",
            "6       P     0.586022     0.617251  0.031229\n",
            "0       D     0.573464     0.600536  0.027072\n",
            "4       I     0.536717     0.563715  0.026998\n",
            "2       F     0.529101     0.549669  0.020568\n",
            "9       T     0.545024     0.561611  0.016588\n",
            "7      SC     0.522472     0.532058  0.009587\n",
            "5       N     0.584906     0.582656 -0.002250\n",
            "3       G     0.537906     0.516245 -0.021661\n"
          ]
        }
      ],
      "source": [
        "pc_rf_a0 = per_country_acc(logreg_a0, X_test_0, y_test_0, pre0)\n",
        "pc_rf_a1 = per_country_acc(logreg_a1, X_test_1, y_test_1, pre1)\n",
        "\n",
        "if pc_rf_a0 is not None and pc_rf_a1 is not None:\n",
        "    pc = pc_rf_a0.merge(pc_rf_a1, on=\"Country\", suffixes=(\"_A0\", \"_A1\"))\n",
        "    pc[\"lift\"] = pc[\"accuracy_A1\"] - pc[\"accuracy_A0\"]\n",
        "    print(\"\\nPer-Country Accuracy Comparison:\")\n",
        "    print(pc.sort_values(\"lift\", ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Profit Calculations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Margin Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "m = m_\\text{profit} + m_\\text{operations} + m_\\text{risk}(A)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "m_\\text{risk}(A) = k \\cdot (1 - A)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Demand Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "V(m) = \\alpha \\cdot m^{-\\epsilon}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Profit Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "\\Pi(m_\\text{profit}) = V(m) \\cdot m_\\text{profit} \\cdot b = \\alpha \\cdot m^{-\\epsilon} \\cdot m_\\text{profit} \\cdot b\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optimal Profit Margin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We take the derivative and set it to zero to find the value of the decision variable `m_profit` that gives the highest (maximum) profit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "[\n",
        "\\frac{d\\Pi}{dm_\\text{profit}} = 0\n",
        "]\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lats denote:\n",
        "$$\n",
        "C = m_\\text{operations} + m_\\text{risk}(A)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "\\frac{\\mathrm{d}}{\\mathrm{d}m_{profit}}\\left[{\\alpha} \\left(m_{profit} + C\\right)^{-{\\epsilon}} m_{profit} b\\right] = 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "m_\\text{profit}^* = \\frac{C}{\\epsilon - 1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Kudos to https://www.derivative-calculator.net/ for helping with derivative calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimal total margin:\n",
        "$$\n",
        "m^* = m_\\text{profit}^* + C = \\frac{\\epsilon \\, C}{\\epsilon - 1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Maximum Profit at Optimum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "$$\n",
        "\\Pi^* = \\alpha \\cdot \\left(\\frac{\\epsilon}{\\epsilon-1} C \\right)^{-\\epsilon} \\cdot \\frac{C}{\\epsilon-1} \\cdot b\n",
        "$$\n",
        "then\n",
        "$$\n",
        "\\Pi^* = \\alpha \\, b \\cdot \\frac{1}{\\epsilon-1} \\cdot \\left(\\frac{\\epsilon}{\\epsilon-1} \\right)^{-\\epsilon} C^{1-\\epsilon}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "For ( \\epsilon = 3 ):\n",
        "\\Pi^* = \\alpha \\, b \\cdot \\frac{4}{27} \\cdot C^{-2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Profit Increase from Increase in Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "\\Delta\\Pi^* = \\Pi^*\\left(A_1\\right) - \\Pi^*\\left(A_0\\right)\n",
        "$$\n",
        "where\n",
        "$$\n",
        "\\Pi^*(A) = \\frac{4 \\alpha b}{27} \\cdot [C(A)]^{-2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A0 Accuracy: 0.5198\n",
            "A1 Accuracy: 0.5306\n",
            "\n",
            "Overall Profit (USD/yr): 2254.38\n",
            "\n",
            "Per-Country Profit Comparison:\n",
            "  Country  accuracy_A0  accuracy_A1  DeltaPi_USDyr\n",
            "6       P     0.586022     0.633423   15964.838849\n",
            "1       E     0.516744     0.561069    9943.918730\n",
            "9       T     0.528436     0.568720    9517.203214\n",
            "8      SP     0.539589     0.577713    9516.988694\n",
            "0       D     0.572573     0.603217    9030.414901\n",
            "4       I     0.537797     0.562635    5910.834438\n",
            "5       N     0.590296     0.607046    5254.645432\n",
            "2       F     0.533069     0.553642    4715.615487\n",
            "3       G     0.530686     0.537906    1575.733898\n",
            "7      SC     0.522472     0.521935    -110.011279\n"
          ]
        }
      ],
      "source": [
        "# Constants from assignment\n",
        "m_operations = 0.03\n",
        "k = 0.3\n",
        "alpha = 1000\n",
        "epsilon = 3\n",
        "b = 12.0\n",
        "\n",
        "# Margin decomposition: m = m_profit + m_operations + m_risk(A)\n",
        "# where:\n",
        "# - m_profit: adjustable profit component\n",
        "# - m_operations: fixed operational cost margin\n",
        "# - m_risk(A): risk margin that depends on accuracy A\n",
        "\n",
        "def m_risk(A):\n",
        "    \"\"\"Risk margin function: m_risk(A) = k * (1 - A)\"\"\"\n",
        "    return k * (1.0 - A)\n",
        "\n",
        "def C(A):\n",
        "    \"\"\"Cost function: C(A) = m_operations + m_risk(A)\n",
        "    Represents the fixed cost components that don't depend on m_profit.\n",
        "    \"\"\"\n",
        "    return m_operations + m_risk(A)\n",
        "\n",
        "def profit_star(A):\n",
        "    \"\"\"Optimal profit function for epsilon=3.\n",
        "    \n",
        "    This is the result of optimizing (m_profit) = V(m) * m_profit * b\n",
        "    where:\n",
        "    - V(m) =  * m^(-) is the demand function\n",
        "    - m = m_profit + C(A) is the total margin\n",
        "    - The optimal m_profit is found by maximizing  with respect to m_profit\n",
        "    \n",
        "    For epsilon=3, the optimized profit is: (4 *  * b / 27) * C(A)^(-2)\n",
        "    \"\"\"\n",
        "    return (4 * alpha * b / 27.0) * (C(A) ** -2)\n",
        "\n",
        "# Calculate profit for best models (using Random Forest)\n",
        "A0_acc = res_rf_a0[\"acc\"]\n",
        "A1_acc = res_rf_a1[\"acc\"]\n",
        "\n",
        "print(f\"A0 Accuracy: {A0_acc:.4f}\")\n",
        "print(f\"A1 Accuracy: {A1_acc:.4f}\")\n",
        "print(f\"\\nOverall Profit (USD/yr): {profit_star(A1_acc) - profit_star(A0_acc):.2f}\")\n",
        "\n",
        "# Per-country profit (if available)\n",
        "if pc_rf_a0 is not None and pc_rf_a1 is not None:\n",
        "    pc_val = pc_rf_a0.merge(pc_rf_a1, on=\"Country\", suffixes=(\"_A0\", \"_A1\")).copy()\n",
        "    pc_val[\"DeltaPi_USDyr\"] = profit_star(pc_val[\"accuracy_A1\"]) - profit_star(pc_val[\"accuracy_A0\"])\n",
        "    print(\"\\nPer-Country Profit Comparison:\")\n",
        "    print(pc_val.sort_values(\"DeltaPi_USDyr\", ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results and Conclusions\n",
        "\n",
        "### Summary of Results\n",
        "\n",
        "The models have been trained and evaluated on both A0 (limited features) and A1 (extended features with betting odds) datasets. Key findings:\n",
        "\n",
        "1. **Model Performance**: All models show similar performance, with slight variations between A0 and A1 datasets.\n",
        "\n",
        "2. **Feature Impact**: The addition of betting odds features (A1) provides additional information that may improve predictions.\n",
        "\n",
        "3. **Best Models**: Random Forest and XGBoost generally perform well, with Logistic Regression providing a baseline comparison.\n",
        "\n",
        "4. **Economic Impact**: The profit calculations show the economic value of improved accuracy in the betting context.\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- Time series cross-validation is crucial to prevent data leakage\n",
        "- Feature engineering (rolling averages, market features) adds valuable information\n",
        "- Threshold optimization can improve model performance for specific use cases\n",
        "- Per-country analysis reveals variations in model performance across different leagues\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Further hyperparameter tuning could be explored\n",
        "- Feature importance analysis could identify the most predictive features\n",
        "- Ensemble methods could potentially improve performance\n",
        "- Additional feature engineering based on domain knowledge\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
